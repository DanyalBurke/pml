{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Rectified Linear Unit (relu Function) x if x > 0 else x\n",
    "\n",
    "    :param Z: input tensor\n",
    "    :return:  Relu output,  and input stored in cache\n",
    "    \"\"\"\n",
    "    A = np.maximum(0, Z)\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Sigmoid Function\n",
    "\n",
    "    :param Z: input tensor\n",
    "    :return: Sigmoid output and input stored in cache\n",
    "    \"\"\"\n",
    "\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Derivative of relu function\n",
    "\n",
    "    :param dA:\n",
    "    :param cache:\n",
    " \n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)  # just converting dz to a correct object.\n",
    "\n",
    "    # When z <= 0, you should set dz to 0 as well.\n",
    "    dZ[Z <= 0] = 0\n",
    "\n",
    "    assert (dZ.shape == Z.shape)\n",
    "\n",
    "    return dZ\n",
    "\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Derivative of sigmoid function\n",
    "\n",
    "    :param dA:\n",
    "    :param cache:\n",
    "    \n",
    "    :return:\n",
    "    \"\"\"\n",
    "    Z = cache\n",
    "\n",
    "    s = 1 / (1 + np.exp(-Z))\n",
    "    dZ = dA * s * (1 - s)\n",
    "\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(n_x, n_h1, n_h2, n_y):\n",
    "    \"\"\"\n",
    "\n",
    "    Initialize weights tensor\n",
    "\n",
    "    :param n_x: size of the input layer\n",
    "    :param n_h1: size of the hidden layer 1\n",
    "    :param n_h2: size of the hidden layer 2\n",
    "    :param n_y: size of the output layer\n",
    "\n",
    "    :return:     weights -- python dictionary containing initialized weights:\n",
    "                    W1 -- weight matrix of shape (n_h1, n_x)\n",
    "                    b1 -- bias vector of shape (n_h1, 1)\n",
    "                    W2 -- weight matrix of shape (n_h2, n_h1)\n",
    "                    b2 -- bias vector of shape (n_h2, 1)\n",
    "                    W3 -- weight matrix of shape (n_y, n_h2)\n",
    "                    b3 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "\n",
    "    W1 = np.random.randn(n_h1, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h1, 1))\n",
    "    W2 = np.random.randn(n_h2, n_h1) * 0.01\n",
    "    b2 = np.zeros((n_h2, 1))\n",
    "    W3 = np.random.randn(n_y, n_h2) * 0.01\n",
    "    b3 = np.zeros((n_y, 1))\n",
    "\n",
    "    assert (W1.shape == (n_h1, n_x))\n",
    "    assert (b1.shape == (n_h1, 1))\n",
    "    assert (W2.shape == (n_h2, n_h1))\n",
    "    assert (b2.shape == (n_h2, 1))\n",
    "    assert (W3.shape == (n_y, n_h2))\n",
    "    assert (b3.shape == (n_y, 1))\n",
    "\n",
    "    weights = {\n",
    "            \"W1\": W1,\n",
    "            \"b1\": b1,\n",
    "            \"W2\": W2,\n",
    "            \"b2\": b2,\n",
    "            \"W3\": W3,\n",
    "            \"b3\": b3\n",
    "    }\n",
    "\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_forward(A, W, b, activation_function):\n",
    "    \"\"\"\n",
    "    Step forward one layer in a deep neural network\n",
    "\n",
    "    :param A: Input tensor for the layer\n",
    "    :param W: Weight tensor for the layer\n",
    "    :param b: Bias tensor for the layer\n",
    "    :param activation_function: Activation function to be applied to the layer\n",
    "\n",
    "    :return: Output Activation tensor and inputs stored in cache\n",
    "    \"\"\"\n",
    "\n",
    "    Z = np.matmul(W, A) + b\n",
    "\n",
    "    assert (Z.shape == (W.shape[0], A.shape[1]))\n",
    "    linear_cache = (A, W, b)\n",
    "\n",
    "    A_next, activation_cache = activation_function(Z)\n",
    "\n",
    "    assert (A_next.shape == (W.shape[0], A_next.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A_next, cache\n",
    "\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "\n",
    "    Cross Entropy Error (Cost) between Y-Hat and Y  (Y-Hat is activation of Lth Layer hence AL)\n",
    "\n",
    "    :param AL: Activation of Lth Layer i.e Y-Hat\n",
    "    :param Y: Actual Labels (Ground Truth)\n",
    "\n",
    "    :return: Cost (How close are we?)\n",
    "\n",
    "    \"\"\"\n",
    "    m = Y.shape[1]\n",
    "    cost = -(np.sum(Y * np.log(AL) + (1 - Y) * np.log(1 - AL))) / m\n",
    "    cost = np.squeeze(cost)\n",
    "    assert (cost.shape == ())\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "def step_backward(dA, cache, activation_function_backward):\n",
    "    \"\"\"\n",
    "    Step back one layer in deep neural network,\n",
    "    i.e Find out how much adjustment is needed in weights in this layer\n",
    "\n",
    "    :param dA:\n",
    "    :param cache:\n",
    "    :param activation_function_backward:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "\n",
    "    dZ = activation_function_backward(dA, activation_cache)\n",
    "\n",
    "    A_prev, W, b = linear_cache\n",
    "    N = A_prev.shape[1]\n",
    "\n",
    "    dW = np.matmul(dZ, A_prev.transpose()) / N\n",
    "    db = np.sum(dZ, axis=1, keepdims=True) / N\n",
    "    dA_prev = np.matmul(W.transpose(), dZ)\n",
    "\n",
    "\n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def update_weights(weights, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update weights across all layers\n",
    "    After our back-propogation we know how much weight & bias adjustment is needed\n",
    "    in each layer, This function performs that update.\n",
    "\n",
    "    :param weights: Original weights\n",
    "    :param grads: Changes that needs to be made to weights\n",
    "    :param learning_rate: learning rate of algorithm. (a step length in gradient descent)\n",
    "\n",
    "    :return: updated weigths\n",
    "    \"\"\"\n",
    "    L = len(weights)//2    # number of layers in the neural network\n",
    "\n",
    "    for l in range(L):\n",
    "        weights[\"W\" + str(l + 1)] = weights[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        weights[\"b\" + str(l + 1)] = weights[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_3_layer_model(X, Y, layers_dims, learning_rate=0.0075, num_iterations=10000, print_cost=False):\n",
    "\n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []  # to keep track of the cost\n",
    "    m = X.shape[1]  # number of examples\n",
    "    \n",
    "    (n_x, n_h1, n_h2, n_y) = layers_dims\n",
    "\n",
    "    weights = init_weights(n_x, n_h1, n_h2, n_y)\n",
    "\n",
    "    # gradient descent\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: (LINEAR -> RELU) * 2 -> LINEAR -> SIGMOID.\n",
    "\n",
    "        # Retrieve W1, b1, W2, b2 from weights\n",
    "        W1 = weights[\"W1\"]\n",
    "        b1 = weights[\"b1\"]\n",
    "        W2 = weights[\"W2\"]\n",
    "        b2 = weights[\"b2\"]\n",
    "        W3 = weights[\"W3\"]\n",
    "        b3 = weights[\"b3\"]\n",
    "\n",
    "\n",
    "        A1, cache1 = step_forward(X, W1, b1, relu)\n",
    "        A2, cache2 = step_forward(A1, W2, b2, relu)\n",
    "        A3, cache3 = step_forward(A2, W3, b3, sigmoid)\n",
    "\n",
    "        cost = compute_cost(A3, Y)\n",
    "\n",
    "        # Initializing backward propagation\n",
    "        dA3 = - (np.divide(Y, A3) - np.divide(1 - Y, 1 - A3))\n",
    "\n",
    "        # Backward propagation.\n",
    "        dA2, dW3, db3 = step_backward(dA3, cache3, sigmoid_backward)\n",
    "        dA1, dW2, db2 = step_backward(dA2, cache2, relu_backward)\n",
    "        dA0, dW1, db1 = step_backward(dA1, cache1, relu_backward)\n",
    "\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        grads['dW3'] = dW3\n",
    "        grads['db3'] = db3\n",
    "\n",
    "\n",
    "        # Update weights.\n",
    "        weights = update_weights(weights, grads, learning_rate)\n",
    "\n",
    "\n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "    # plot the cost\n",
    "\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of data = 1797\n",
      "1797\n",
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "print(f'len of data = {len(digits.data)}')\n",
    "print(len(images_and_labels))\n",
    "plt.figure(figsize=(8,6))\n",
    "for index, (image, label) in enumerate(images_and_labels[1:6]):\n",
    "    plt.subplot(1, 6, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "print(digits.keys())\n",
    "# print(digits['DESCR'])\n",
    "# print(len(digits['data'][0]))\n",
    "# print(len(digits['data']))\n",
    "# print(digits['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the digits dataset\n",
    "N = len(digits.data)\n",
    "X = digits.data\n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "target_temp = digits.target.reshape(-1,1)\n",
    "encoder.fit(target_temp)\n",
    "Y = encoder.transform(target_temp).toarray()\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = np.transpose(X_train)\n",
    "X_test = np.transpose(X_test)\n",
    "Y_train = np.transpose(Y_train)\n",
    "Y_test = np.transpose(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 6.9337754140142325\n",
      "Cost after iteration 100: 3.271578220322025\n",
      "Cost after iteration 200: 3.270022413903926\n",
      "Cost after iteration 300: 3.268442260472516\n",
      "Cost after iteration 400: 3.2663557672959245\n",
      "Cost after iteration 500: 3.262618494692561\n",
      "Cost after iteration 600: 3.253073909194501\n",
      "Cost after iteration 700: 3.213067053157645\n",
      "Cost after iteration 800: 2.9276733467399394\n",
      "Cost after iteration 900: 2.4317231059329805\n",
      "Cost after iteration 1000: 2.0726213697042954\n",
      "Cost after iteration 1100: 1.9189583478394585\n",
      "Cost after iteration 1200: 1.7711967482362891\n",
      "Cost after iteration 1300: 1.579725180166698\n",
      "Cost after iteration 1400: 1.2846667673705825\n",
      "Cost after iteration 1500: 1.0648440070615577\n",
      "Cost after iteration 1600: 0.9285833654590022\n",
      "Cost after iteration 1700: 0.8290576218131815\n",
      "Cost after iteration 1800: 0.7482595022039127\n",
      "Cost after iteration 1900: 0.6776640318118191\n",
      "Cost after iteration 2000: 0.6158503297715262\n",
      "Cost after iteration 2100: 0.5614767850562544\n",
      "Cost after iteration 2200: 0.5135494636413027\n",
      "Cost after iteration 2300: 0.46957923564011694\n",
      "Cost after iteration 2400: 0.4290451309396304\n",
      "Cost after iteration 2500: 0.39255875160760934\n",
      "Cost after iteration 2600: 0.3588481221253051\n",
      "Cost after iteration 2700: 0.32878989162025135\n",
      "Cost after iteration 2800: 0.30241835146879353\n",
      "Cost after iteration 2900: 0.2790962172343895\n",
      "Cost after iteration 3000: 0.25783935197841734\n",
      "Cost after iteration 3100: 0.23871899094599341\n",
      "Cost after iteration 3200: 0.2215311244058027\n",
      "Cost after iteration 3300: 0.20594288074963352\n",
      "Cost after iteration 3400: 0.19186107977473624\n",
      "Cost after iteration 3500: 0.17918820399072846\n",
      "Cost after iteration 3600: 0.16748811470098957\n",
      "Cost after iteration 3700: 0.15671129551668797\n",
      "Cost after iteration 3800: 0.14691898240228288\n",
      "Cost after iteration 3900: 0.1378054365474891\n",
      "Cost after iteration 4000: 0.12953921873332747\n",
      "Cost after iteration 4100: 0.12192782574932663\n",
      "Cost after iteration 4200: 0.11469074113606421\n",
      "Cost after iteration 4300: 0.10803153203005735\n",
      "Cost after iteration 4400: 0.10188043815952405\n",
      "Cost after iteration 4500: 0.09613792384150646\n",
      "Cost after iteration 4600: 0.09079019724794224\n",
      "Cost after iteration 4700: 0.08584782123386946\n",
      "Cost after iteration 4800: 0.081263107082959\n",
      "Cost after iteration 4900: 0.07702363169994413\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_x = 64\n",
    "n_h1 = 40\n",
    "n_h2 = 30\n",
    "n_y = 10\n",
    "layers_dims = (n_x, n_h1, n_h2, n_y)\n",
    "\n",
    "weights = nn_3_layer_model(X_train, Y_train, layers_dims = (n_x, n_h1, n_h2, n_y), num_iterations = 5000, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9850374064837906\n",
      "Accuracy: 0.9124579124579124\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = compute_accuracy(X_train, Y_train, weights)\n",
    "accuracy_test = compute_accuracy(X_test, Y_test, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test[:,[1]]\n",
    "ax_test = X_test[:, [19, 55, 300]]\n",
    "ay_test = Y_test[:, [19, 55, 300]]\n",
    "print(ay_test)\n",
    "predict(ax_test, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
