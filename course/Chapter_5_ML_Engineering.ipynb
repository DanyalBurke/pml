{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [ 3  4]\n",
      " [ 1  2]\n",
      " [ 8  9]\n",
      " [11 12]]\n",
      "[0 0 1 0 2 2]\n",
      "[[ 6  7]\n",
      " [ 5  6]\n",
      " [ 9 10]]\n",
      "[1 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [5, 6], [6, 7], [8, 9], [9, 10], [11, 12]])\n",
    "Y = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
    "print(X_train)\n",
    "print(Y_train)\n",
    "print(X_test)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kfold train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=None, shuffle=False)\n",
      "train indices: [3 4 5 6 7 8] test indices: [0 1 2]\n",
      "train indices: [0 1 2 6 7 8] test indices: [3 4 5]\n",
      "train indices: [0 1 2 3 4 5] test indices: [6 7 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [5, 6], [6, 7], [8, 9], [9, 10], [11, 12]])\n",
    "Y = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "print(kf)  \n",
    "for train_index, test_index in kf.split(X, Y):\n",
    "   print(\"train indices:\", train_index, \"test indices:\", test_index)\n",
    "   X_train, X_test = X[train_index], X[test_index]\n",
    "   Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "#    print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified KFold split: Classes are distributed across the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
      "train indices: [1 2 4 5 7 8] test indices: [0 3 6]\n",
      "train indices: [0 2 3 5 6 8] test indices: [1 4 7]\n",
      "train indices: [0 1 3 4 6 7] test indices: [2 5 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [5, 6], [6, 7], [8, 9], [9, 10], [11, 12]])\n",
    "Y = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "print(skf)  \n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "   print(\"train indices:\", train_index, \"test indices:\", test_index)\n",
    "   X_train, X_test = X[train_index], X[test_index]\n",
    "   y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying neural networks hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Best: 0.940700 using {'batch_size': 32, 'epochs': 10}\n",
      "0.917533 (0.004669) with: {'batch_size': 32, 'epochs': 5}\n",
      "0.929517 (0.001445) with: {'batch_size': 32, 'epochs': 7}\n",
      "0.940700 (0.001471) with: {'batch_size': 32, 'epochs': 10}\n",
      "0.913233 (0.003233) with: {'batch_size': 50, 'epochs': 5}\n",
      "0.919100 (0.003311) with: {'batch_size': 50, 'epochs': 7}\n",
      "0.929033 (0.002597) with: {'batch_size': 50, 'epochs': 10}\n",
      "0.891650 (0.001961) with: {'batch_size': 100, 'epochs': 5}\n",
      "0.899700 (0.005700) with: {'batch_size': 100, 'epochs': 7}\n",
      "0.910833 (0.001978) with: {'batch_size': 100, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(40, activation='relu', input_shape=(28*28,)))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=SGD(),\n",
    "                metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 28*28)\n",
    "X_test = X_test.reshape(10000, 28*28)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalize\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# Encode Y as binary class vector\n",
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "#Wrapper to make keras model work with scikitlearn\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [32, 50, 100]\n",
    "epochs = [5, 7, 10]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv = 3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# # summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying neural network's layers and neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_296 (Dense)            (None, 40)                31400     \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 32,430\n",
      "Trainable params: 32,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_299 (Dense)            (None, 40)                31400     \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 32,430\n",
      "Trainable params: 32,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_302 (Dense)            (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, 10)                160       \n",
      "=================================================================\n",
      "Total params: 24,175\n",
      "Trainable params: 24,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_305 (Dense)            (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 10)                160       \n",
      "=================================================================\n",
      "Total params: 24,175\n",
      "Trainable params: 24,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_308 (Dense)            (None, 60)                47100     \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, 50)                3050      \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 40)                2040      \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "dense_312 (Dense)            (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 54,250\n",
      "Trainable params: 54,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_314 (Dense)            (None, 60)                47100     \n",
      "_________________________________________________________________\n",
      "dense_315 (Dense)            (None, 50)                3050      \n",
      "_________________________________________________________________\n",
      "dense_316 (Dense)            (None, 40)                2040      \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "dense_318 (Dense)            (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 54,250\n",
      "Trainable params: 54,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_320 (Dense)            (None, 40)                31400     \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 32,430\n",
      "Trainable params: 32,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_323 (Dense)            (None, 40)                31400     \n",
      "_________________________________________________________________\n",
      "dense_324 (Dense)            (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 32,430\n",
      "Trainable params: 32,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Best: 0.951650 using {'batch_size': 32, 'epochs': 5, 'model_conf': {'hidden_layers': [{'neurons': 40, 'activation': 'relu'}, {'neurons': 20, 'activation': 'relu'}], 'optimizer': <keras.optimizers.Adam object at 0x1a44b10320>}}\n",
      "0.892633 (0.002600) with: {'batch_size': 32, 'epochs': 5, 'model_conf': {'hidden_layers': [{'neurons': 40, 'activation': 'relu'}, {'neurons': 20, 'activation': 'relu'}], 'optimizer': <keras.optimizers.SGD object at 0x1a44b10208>}}\n",
      "0.885533 (0.000233) with: {'batch_size': 32, 'epochs': 5, 'model_conf': {'hidden_layers': [{'neurons': 30, 'activation': 'relu'}, {'neurons': 15, 'activation': 'relu'}], 'optimizer': <keras.optimizers.SGD object at 0x1a44b102b0>}}\n",
      "0.917117 (0.001083) with: {'batch_size': 32, 'epochs': 5, 'model_conf': {'hidden_layers': [{'neurons': 60, 'activation': 'relu'}, {'neurons': 50, 'activation': 'relu'}, {'neurons': 40, 'activation': 'relu'}, {'neurons': 30, 'activation': 'relu'}, {'neurons': 20, 'activation': 'relu'}], 'optimizer': <keras.optimizers.SGD object at 0x1a44b10358>}}\n",
      "0.951650 (0.000117) with: {'batch_size': 32, 'epochs': 5, 'model_conf': {'hidden_layers': [{'neurons': 40, 'activation': 'relu'}, {'neurons': 20, 'activation': 'relu'}], 'optimizer': <keras.optimizers.Adam object at 0x1a44b10320>}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "def create_model(model_conf):\n",
    "    model = Sequential()\n",
    "\n",
    "    #add hidden layers \n",
    "    #print('building nn with conf' + str(model_conf))\n",
    "    hidden_layers = model_conf['hidden_layers']\n",
    "    n_h1 = hidden_layers[0]['neurons'] \n",
    "    n_h1_activation = hidden_layers[0]['activation']\n",
    "    model.add(Dense(n_h1, activation=n_h1_activation, input_shape=(28*28,)))\n",
    "    for layer in hidden_layers[1:]:\n",
    "        neurons = layer['neurons']\n",
    "        activation = layer['activation'] \n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    \n",
    "    #add output_layer     \n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    optimizer = model_conf['optimizer']\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 28*28)\n",
    "X_test = X_test.reshape(10000, 28*28)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalize\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# Encode Y as binary class vector\n",
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "#Wrapper to make keras model work with scikitlearn\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "\n",
    "batch_size = [32]\n",
    "epochs = [5]\n",
    "model_conf = [\n",
    "    { \"hidden_layers\": [{\"neurons\": 40, \"activation\": \"relu\"},\n",
    "                         {\"neurons\": 20, \"activation\": \"relu\"}\n",
    "                        ],\n",
    "       \"optimizer\": SGD(lr=0.005)\n",
    "    },\n",
    "    { \"hidden_layers\": [{\"neurons\": 30, \"activation\": \"relu\"},\n",
    "                         {\"neurons\": 15, \"activation\": \"relu\"},\n",
    "                        ],\n",
    "       \"optimizer\": SGD(lr=0.005)\n",
    "    },\n",
    "    { \"hidden_layers\": [{\"neurons\": 60, \"activation\": \"relu\"},\n",
    "                         {\"neurons\": 50, \"activation\": \"relu\"},\n",
    "                        {\"neurons\": 40, \"activation\": \"relu\"},\n",
    "                        {\"neurons\": 30, \"activation\": \"relu\"},\n",
    "                        {\"neurons\": 20, \"activation\": \"relu\"}\n",
    "                       ],\n",
    "       \"optimizer\": SGD()\n",
    "    },\n",
    "    { \"hidden_layers\": [{\"neurons\": 40, \"activation\": \"relu\"},\n",
    "                         {\"neurons\": 20, \"activation\": \"relu\"}\n",
    "                        ],\n",
    "       \"optimizer\": Adam()\n",
    "    }\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, model_conf=model_conf)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv = 2, refit=False)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.22474487 -0.70710678 -1.22474487]\n",
      " [ 0.          1.41421356  0.        ]\n",
      " [ 1.22474487 -0.70710678  1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1000, 2, 0.0001], [2000, 4, 0.0003], [3000, 2, 0.0005]])\n",
    "scaled_X = preprocessing.scale(X)\n",
    "print(scaled_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.25\n"
     ]
    }
   ],
   "source": [
    "#Mean Squared Error for Regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "Y = [100, 200, 300, 400]\n",
    "Y_hat = [102, 198, 300, 405]\n",
    "\n",
    "mse = mean_squared_error(Y, Y_hat)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "#Accuracy for Classification Problems\n",
    "from sklearn.metrics import accuracy_score\n",
    "Y = [1, 1, 0, 0, 1]\n",
    "Y_hat = [1, 1, 0, 0, 0 ]\n",
    "accuracy = accuracy_score(Y, Y_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.9891089108910891\n",
      "precision = 0.3333333333333333\n",
      "recall = 0.1\n",
      "f1 score = 0.15384615384615383\n",
      "[[998   2]\n",
      " [  9   1]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluation metrics for skewed classes\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 0 is normal class 1 is nearly outlier class\n",
    "Y = [ 0 for i in range(1000)] + [1 for i in range(10)]\n",
    "\n",
    "def dumb_classifier_predict(N):\n",
    "    #returns class 0 for everything except some random ones\n",
    "    res = [0 for i in range(N)]\n",
    "    res[0] = res[5] = res[1002] = 1\n",
    "    return res\n",
    "\n",
    "Y_hat = dumb_classifier_predict(1010)\n",
    "\n",
    "accuracy = accuracy_score(Y, Y_hat)\n",
    "print('accuracy=', accuracy)\n",
    "#even dumb classifiers can have high accuracy in skewed class scenarios\n",
    "#Use precision and recall\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y, Y_hat)\n",
    "print('precision =', precision)\n",
    "recall = recall_score(Y, Y_hat)\n",
    "print('recall =', recall)\n",
    "\n",
    "#For single valued metric on skewed classes use F1 score which combines precision and recall\n",
    "f1 = f1_score(Y, Y_hat)\n",
    "print('f1 score =',f1)\n",
    "\n",
    "#Confusion metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(Y, Y_hat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[206 179 217 197 201]\n",
      " [210 190 202 200 198]\n",
      " [183 204 207 209 197]\n",
      " [186 196 192 216 210]\n",
      " [197 191 207 202 203]]\n",
      "(array([0.20977597, 0.19791667, 0.20195122, 0.2109375 , 0.2011893 ]), array([0.206, 0.19 , 0.207, 0.216, 0.203]), array([0.20787084, 0.19387755, 0.20444444, 0.21343874, 0.20209059]), array([1000, 1000, 1000, 1000, 1000]))\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix for multiclass classification\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "Y = [ 0 for i in range(1000)] + [1 for i in range(1000)] + [2 for i in range(1000)] + [3 for i in range(1000)] + [4 for i in range(1000)]\n",
    "Y_hat = [ random.randint(0,4) for i in range(5000)]\n",
    "\n",
    "#Confusion matrix for multiclass classification\n",
    "print(confusion_matrix(Y, Y_hat))\n",
    "\n",
    "#Precision, Recall, F1 score for each class\n",
    "print(precision_recall_fscore_support(Y, Y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
